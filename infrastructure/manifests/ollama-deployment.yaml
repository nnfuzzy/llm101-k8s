apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-deployment
  namespace: default
  labels:
    app: ollama
    environment: production
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
            #nvidia.com/gpu: 1
          limits:
            cpu: "650m"
            memory: "2Gi"
            #nvidia.com/gpu: 1
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
      volumes:
      - name: ollama-data
        persistentVolumeClaim:
          claimName: ollama-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-pvc
  namespace: default
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ""  # Keep empty for manual binding
  resources:
    requests:
      storage: 10Gi     # Checkout how much you need for the models!
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ollama-pv
  namespace: default
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  capacity:
    storage: 10Gi       # Checkout how much you need for the models!
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ""  # Matches PVC
  local:
    path: /home/ubuntu/.ollama  # Change if neccessary
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - ip-172-31-16-98  # Node where PV is available, e.g. check with "kubectl get nodes -o wide"

---
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
  namespace: default
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  selector:
    app: ollama
  type: NodePort
  ports:
    - protocol: TCP
      port: 11434
      targetPort: 11434
      nodePort: 30000 # Optional if you want to expose the service outside the cluster
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-ollama
  namespace: default
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ollama-deployment
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 65
